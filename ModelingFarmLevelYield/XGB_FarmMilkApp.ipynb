{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "# Set the Optuna logger to output only WARNING and higher levels\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set_context(\"notebook\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>SE_Number</th>\n",
       "      <th>Age</th>\n",
       "      <th>BreedName</th>\n",
       "      <th>LactationNumber</th>\n",
       "      <th>DaysInMilk</th>\n",
       "      <th>YearSeason</th>\n",
       "      <th>DailyYield</th>\n",
       "      <th>PreviousDailyYield</th>\n",
       "      <th>DailyYieldChange</th>\n",
       "      <th>ExpectedYield</th>\n",
       "      <th>NormalizedDailyYield</th>\n",
       "      <th>NormalizedDailyYieldChange</th>\n",
       "      <th>HeatStress</th>\n",
       "      <th>Temp15Threshold</th>\n",
       "      <th>HW</th>\n",
       "      <th>cum_HW</th>\n",
       "      <th>MeanTemperature</th>\n",
       "      <th>MeanTHI_adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>SE-064c0cec-1189</td>\n",
       "      <td>3095</td>\n",
       "      <td>02 SLB</td>\n",
       "      <td>7</td>\n",
       "      <td>191</td>\n",
       "      <td>2022-1</td>\n",
       "      <td>30.77</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.914865</td>\n",
       "      <td>0.856748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.025000</td>\n",
       "      <td>28.012944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>SE-064c0cec-1189</td>\n",
       "      <td>3096</td>\n",
       "      <td>02 SLB</td>\n",
       "      <td>7</td>\n",
       "      <td>192</td>\n",
       "      <td>2022-1</td>\n",
       "      <td>48.22</td>\n",
       "      <td>30.770000</td>\n",
       "      <td>8.725000</td>\n",
       "      <td>35.799613</td>\n",
       "      <td>1.103224</td>\n",
       "      <td>0.243718</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.279167</td>\n",
       "      <td>32.898193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>SE-064c0cec-1189</td>\n",
       "      <td>3097</td>\n",
       "      <td>02 SLB</td>\n",
       "      <td>7</td>\n",
       "      <td>193</td>\n",
       "      <td>2022-1</td>\n",
       "      <td>30.53</td>\n",
       "      <td>39.495000</td>\n",
       "      <td>-2.988333</td>\n",
       "      <td>35.684360</td>\n",
       "      <td>1.023044</td>\n",
       "      <td>-0.083744</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>36.760487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>SE-064c0cec-1189</td>\n",
       "      <td>3098</td>\n",
       "      <td>02 SLB</td>\n",
       "      <td>7</td>\n",
       "      <td>194</td>\n",
       "      <td>2022-1</td>\n",
       "      <td>42.26</td>\n",
       "      <td>36.506667</td>\n",
       "      <td>1.438333</td>\n",
       "      <td>35.569108</td>\n",
       "      <td>1.066796</td>\n",
       "      <td>0.040438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>31.939524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>SE-064c0cec-1189</td>\n",
       "      <td>3099</td>\n",
       "      <td>02 SLB</td>\n",
       "      <td>7</td>\n",
       "      <td>195</td>\n",
       "      <td>2022-1</td>\n",
       "      <td>38.49</td>\n",
       "      <td>37.945000</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>35.453856</td>\n",
       "      <td>1.073339</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.700000</td>\n",
       "      <td>26.498206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483097</th>\n",
       "      <td>2023-06-03</td>\n",
       "      <td>f454e660</td>\n",
       "      <td>SE-fcdf259d-0044-0</td>\n",
       "      <td>4150</td>\n",
       "      <td>41 Fjällko</td>\n",
       "      <td>10</td>\n",
       "      <td>347</td>\n",
       "      <td>2023-3</td>\n",
       "      <td>12.67</td>\n",
       "      <td>14.652000</td>\n",
       "      <td>-0.622000</td>\n",
       "      <td>13.608593</td>\n",
       "      <td>1.030966</td>\n",
       "      <td>-0.045706</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>53.132530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483098</th>\n",
       "      <td>2023-06-04</td>\n",
       "      <td>f454e660</td>\n",
       "      <td>SE-fcdf259d-0044-0</td>\n",
       "      <td>4151</td>\n",
       "      <td>41 Fjällko</td>\n",
       "      <td>10</td>\n",
       "      <td>348</td>\n",
       "      <td>2023-3</td>\n",
       "      <td>22.31</td>\n",
       "      <td>14.030000</td>\n",
       "      <td>0.954000</td>\n",
       "      <td>13.516773</td>\n",
       "      <td>1.108549</td>\n",
       "      <td>0.070579</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.079167</td>\n",
       "      <td>56.726870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483099</th>\n",
       "      <td>2023-06-05</td>\n",
       "      <td>f454e660</td>\n",
       "      <td>SE-fcdf259d-0044-0</td>\n",
       "      <td>4152</td>\n",
       "      <td>41 Fjällko</td>\n",
       "      <td>10</td>\n",
       "      <td>349</td>\n",
       "      <td>2023-3</td>\n",
       "      <td>12.84</td>\n",
       "      <td>14.984000</td>\n",
       "      <td>-0.092000</td>\n",
       "      <td>13.424952</td>\n",
       "      <td>1.109278</td>\n",
       "      <td>-0.006853</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.237500</td>\n",
       "      <td>58.482418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483100</th>\n",
       "      <td>2023-06-06</td>\n",
       "      <td>f454e660</td>\n",
       "      <td>SE-fcdf259d-0044-0</td>\n",
       "      <td>4153</td>\n",
       "      <td>41 Fjällko</td>\n",
       "      <td>10</td>\n",
       "      <td>350</td>\n",
       "      <td>2023-3</td>\n",
       "      <td>9.47</td>\n",
       "      <td>14.892000</td>\n",
       "      <td>-0.284000</td>\n",
       "      <td>13.333131</td>\n",
       "      <td>1.095617</td>\n",
       "      <td>-0.021300</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.345833</td>\n",
       "      <td>60.546358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483101</th>\n",
       "      <td>2023-06-07</td>\n",
       "      <td>f454e660</td>\n",
       "      <td>SE-fcdf259d-0044-0</td>\n",
       "      <td>4154</td>\n",
       "      <td>41 Fjällko</td>\n",
       "      <td>10</td>\n",
       "      <td>351</td>\n",
       "      <td>2023-3</td>\n",
       "      <td>8.97</td>\n",
       "      <td>14.608000</td>\n",
       "      <td>-1.356000</td>\n",
       "      <td>13.241310</td>\n",
       "      <td>1.000807</td>\n",
       "      <td>-0.102407</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.645833</td>\n",
       "      <td>61.559237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>483102 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date FarmName_Pseudo           SE_Number   Age   BreedName  \\\n",
       "0      2022-01-01        a624fb9a    SE-064c0cec-1189  3095      02 SLB   \n",
       "1      2022-01-02        a624fb9a    SE-064c0cec-1189  3096      02 SLB   \n",
       "2      2022-01-03        a624fb9a    SE-064c0cec-1189  3097      02 SLB   \n",
       "3      2022-01-04        a624fb9a    SE-064c0cec-1189  3098      02 SLB   \n",
       "4      2022-01-05        a624fb9a    SE-064c0cec-1189  3099      02 SLB   \n",
       "...           ...             ...                 ...   ...         ...   \n",
       "483097 2023-06-03        f454e660  SE-fcdf259d-0044-0  4150  41 Fjällko   \n",
       "483098 2023-06-04        f454e660  SE-fcdf259d-0044-0  4151  41 Fjällko   \n",
       "483099 2023-06-05        f454e660  SE-fcdf259d-0044-0  4152  41 Fjällko   \n",
       "483100 2023-06-06        f454e660  SE-fcdf259d-0044-0  4153  41 Fjällko   \n",
       "483101 2023-06-07        f454e660  SE-fcdf259d-0044-0  4154  41 Fjällko   \n",
       "\n",
       "        LactationNumber  DaysInMilk YearSeason  DailyYield  \\\n",
       "0                     7         191     2022-1       30.77   \n",
       "1                     7         192     2022-1       48.22   \n",
       "2                     7         193     2022-1       30.53   \n",
       "3                     7         194     2022-1       42.26   \n",
       "4                     7         195     2022-1       38.49   \n",
       "...                 ...         ...        ...         ...   \n",
       "483097               10         347     2023-3       12.67   \n",
       "483098               10         348     2023-3       22.31   \n",
       "483099               10         349     2023-3       12.84   \n",
       "483100               10         350     2023-3        9.47   \n",
       "483101               10         351     2023-3        8.97   \n",
       "\n",
       "        PreviousDailyYield  DailyYieldChange  ExpectedYield  \\\n",
       "0                 0.000000          0.000000      35.914865   \n",
       "1                30.770000          8.725000      35.799613   \n",
       "2                39.495000         -2.988333      35.684360   \n",
       "3                36.506667          1.438333      35.569108   \n",
       "4                37.945000          0.109000      35.453856   \n",
       "...                    ...               ...            ...   \n",
       "483097           14.652000         -0.622000      13.608593   \n",
       "483098           14.030000          0.954000      13.516773   \n",
       "483099           14.984000         -0.092000      13.424952   \n",
       "483100           14.892000         -0.284000      13.333131   \n",
       "483101           14.608000         -1.356000      13.241310   \n",
       "\n",
       "        NormalizedDailyYield  NormalizedDailyYieldChange  HeatStress  \\\n",
       "0                   0.856748                    0.000000           0   \n",
       "1                   1.103224                    0.243718           0   \n",
       "2                   1.023044                   -0.083744           0   \n",
       "3                   1.066796                    0.040438           0   \n",
       "4                   1.073339                    0.003074           0   \n",
       "...                      ...                         ...         ...   \n",
       "483097              1.030966                   -0.045706           0   \n",
       "483098              1.108549                    0.070579           0   \n",
       "483099              1.109278                   -0.006853           0   \n",
       "483100              1.095617                   -0.021300           0   \n",
       "483101              1.000807                   -0.102407           0   \n",
       "\n",
       "        Temp15Threshold  HW  cum_HW  MeanTemperature  MeanTHI_adj  \n",
       "0                     0   0       0        -3.025000    28.012944  \n",
       "1                     0   0       0        -0.279167    32.898193  \n",
       "2                     0   0       0         2.033333    36.760487  \n",
       "3                     0   0       0         0.066667    31.939524  \n",
       "4                     0   0       0        -3.700000    26.498206  \n",
       "...                 ...  ..     ...              ...          ...  \n",
       "483097                1   0       0        12.666667    53.132530  \n",
       "483098                1   0       0        13.079167    56.726870  \n",
       "483099                1   0       0        14.237500    58.482418  \n",
       "483100                1   0       0        15.345833    60.546358  \n",
       "483101                1   0       0        15.645833    61.559237  \n",
       "\n",
       "[483102 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype_dict = {\n",
    "    'Date': 'str',\n",
    "    'FarmName_Pseudo': 'str',\n",
    "    'SE_Number': 'str',\n",
    "    'Age': 'Int64',\n",
    "    'BreedName': 'str',\n",
    "    'DailyYield': 'float',\n",
    "    'PreviousDailyYield': 'float',\n",
    "    'DailyYieldChange': 'float',\n",
    "    'DaysInMilk': 'Int64',\n",
    "    'YearSeason': 'str',\n",
    "    'LactationNumber': 'Int64',\n",
    "    'ExpectedYield': 'float',\n",
    "    'NormalizedDailyYield': 'float',\n",
    "    'NormalizedDailyYieldChange': 'float',\n",
    "    'HeatStress': 'Int64',\n",
    "    'Temp15Threshold': 'Int64',\n",
    "    'HW': 'Int64',\n",
    "    'cum_HW': 'Int64',\n",
    "    'MeanTemperature': 'float',\n",
    "    'MeanTHI_adj': 'float'\n",
    "}\n",
    "\n",
    "milk_data = pd.read_csv('../Data/MergedData/MilkApproachYieldData.csv', dtype=dtype_dict)\n",
    "milk_data['Date'] = pd.to_datetime(milk_data['Date'], format='%Y-%m-%d')\n",
    "milk_data.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline mean of NormalizedDailyYield for all days: 1.0002\n",
      "\n",
      "Selected features: ['MeanTemperature', 'HW']\n",
      "Best parameters: {'lambda': 0.0004481574143079313, 'alpha': 0.6173102077760996, 'subsample': 0.9860651620899856, 'colsample_bytree': 0.670473021702612, 'learning_rate': 0.08779046356804424, 'n_estimators': 696, 'max_depth': 4}\n",
      "Final model performance: MSE = 0.0107 ± 0.0029\n",
      "Mean Squared Error on test set: 0.0074\n",
      "Estimated average milk production during heat stress: 0.9825\n",
      "Reduction in milk production during heat stress: 1.77%\n",
      "\n",
      "Selected features: ['MeanTemperature', 'cum_HW']\n",
      "Best parameters: {'lambda': 1.852183385268695e-05, 'alpha': 0.003204572046942967, 'subsample': 0.526542119828887, 'colsample_bytree': 0.5962659642410891, 'learning_rate': 0.008608121330926555, 'n_estimators': 848, 'max_depth': 6}\n",
      "Final model performance: MSE = 0.0107 ± 0.0029\n",
      "Mean Squared Error on test set: 0.0074\n",
      "Estimated average milk production during heat stress: 0.9825\n",
      "Reduction in milk production during heat stress: 1.77%\n",
      "\n",
      "Selected features: ['MeanTHI_adj', 'HW']\n",
      "Best parameters: {'lambda': 0.0006205491838436579, 'alpha': 1.9414508944873717e-06, 'subsample': 0.6470852981383091, 'colsample_bytree': 0.7955645846475726, 'learning_rate': 0.004914342350370191, 'n_estimators': 989, 'max_depth': 8}\n",
      "Final model performance: MSE = 0.0107 ± 0.0029\n",
      "Mean Squared Error on test set: 0.0074\n",
      "Estimated average milk production during heat stress: 0.9826\n",
      "Reduction in milk production during heat stress: 1.76%\n",
      "\n",
      "Selected features: ['MeanTHI_adj', 'cum_HW']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-08-02 13:57:53,421] Trial 26 failed with parameters: {'lambda': 4.2630399017226016e-07, 'alpha': 9.433043435560652e-05, 'subsample': 0.7604092029079305, 'colsample_bytree': 0.8687179766262431, 'learning_rate': 0.017384580393649124, 'n_estimators': 507, 'max_depth': 8} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/n0/fphw_xw93vv749r_ntt01qd80000gn/T/ipykernel_15187/3643896788.py\", line 49, in objective\n",
      "    scores = cross_val_score(model, train_heatstress[features], train_heatstress[target], cv=5, scoring='neg_mean_squared_error')\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 712, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "                 ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 423, in cross_validate\n",
      "    results = parallel(\n",
      "              ^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 67, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 129, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/xgboost/core.py\", line 2051, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2024-08-02 13:57:53,429] Trial 26 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 90\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Train the model with the feature combinations on the training set and print results\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m features \u001b[38;5;129;01min\u001b[39;00m feature_combinations:\n\u001b[0;32m---> 90\u001b[0m     avg_prod_heatstress, reduction \u001b[38;5;241m=\u001b[39m \u001b[43mfit_xgboost_and_print_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_heatstress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_heatstress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline_mean\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 59\u001b[0m, in \u001b[0;36mfit_xgboost_and_print_results\u001b[0;34m(train_data, test_data, features, baseline_mean)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Optimize hyperparameters using Optuna\u001b[39;00m\n\u001b[1;32m     58\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[3], line 49\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Cross-validation to estimate performance\u001b[39;00m\n\u001b[1;32m     48\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparam)\n\u001b[0;32m---> 49\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_heatstress\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_heatstress\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneg_mean_squared_error\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m mse \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mscores\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mse\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:423\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 423\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/xgboost/sklearn.py:1090\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m (\n\u001b[1;32m   1082\u001b[0m     model,\n\u001b[1;32m   1083\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1088\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1089\u001b[0m )\n\u001b[0;32m-> 1090\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/xgboost/core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m     _check_call(\n\u001b[0;32m-> 2051\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2054\u001b[0m     )\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Specify the farm ID for analysis\n",
    "farm_id = 'a624fb9a'\n",
    "\n",
    "# Filter data for the specific farm\n",
    "farm_data = milk_data[milk_data['FarmName_Pseudo'] == farm_id]\n",
    "\n",
    "# Calculate the baseline (mean of NormalizedDailyYield for all days at the farm)\n",
    "baseline_mean = farm_data['NormalizedDailyYield'].mean()\n",
    "print(f\"Baseline mean of NormalizedDailyYield for all days: {baseline_mean:.4f}\")\n",
    "\n",
    "# Define the feature combinations\n",
    "feature_combinations = [\n",
    "    ['MeanTemperature', 'HW'],\n",
    "    ['MeanTemperature', 'cum_HW'],\n",
    "    ['MeanTHI_adj', 'HW'],\n",
    "    ['MeanTHI_adj', 'cum_HW']\n",
    "]\n",
    "\n",
    "# Define target variable\n",
    "target = 'NormalizedDailyYield'\n",
    "\n",
    "# Filter data for heat stress conditions\n",
    "data_heatstress = farm_data[farm_data['HeatStress'] == 1]\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_heatstress, test_heatstress = train_test_split(data_heatstress, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the continuous features (MeanTemperature and MeanTHI_adj)\n",
    "scaler = StandardScaler()\n",
    "train_heatstress[['MeanTemperature', 'MeanTHI_adj']] = scaler.fit_transform(train_heatstress[['MeanTemperature', 'MeanTHI_adj']])\n",
    "test_heatstress[['MeanTemperature', 'MeanTHI_adj']] = scaler.transform(test_heatstress[['MeanTemperature', 'MeanTHI_adj']])\n",
    "\n",
    "# Function to optimize hyperparameters using Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'verbosity': 0,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 15),\n",
    "    }\n",
    "\n",
    "    # Cross-validation to estimate performance\n",
    "    model = xgb.XGBRegressor(**param)\n",
    "    scores = cross_val_score(model, train_heatstress[features], train_heatstress[target], cv=5, scoring='neg_mean_squared_error')\n",
    "    mse = -scores.mean()\n",
    "    return mse\n",
    "\n",
    "# Function to fit the model and print results\n",
    "def fit_xgboost_and_print_results(train_data, test_data, features, baseline_mean):\n",
    "    print(f\"\\nSelected features: {features}\")\n",
    "\n",
    "    # Optimize hyperparameters using Optuna\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "    best_params = study.best_params\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "    # Train final model using the best parameters\n",
    "    best_model = xgb.XGBRegressor(**best_params)\n",
    "    best_model.fit(train_data[features], train_data[target])\n",
    "\n",
    "    # K-Fold Cross-Validation for final model evaluation\n",
    "    final_scores = cross_val_score(best_model, train_data[features], train_data[target], cv=5, scoring='neg_mean_squared_error')\n",
    "    final_mse = -final_scores.mean()\n",
    "    final_std = final_scores.std()\n",
    "    print(f\"Final model performance: MSE = {final_mse:.4f} ± {final_std:.4f}\")\n",
    "\n",
    "    # Predictions and evaluation on the test set\n",
    "    y_pred = best_model.predict(test_data[features])\n",
    "    mse = mean_squared_error(test_data[target], y_pred)\n",
    "    print(f\"Mean Squared Error on test set: {mse:.4f}\")\n",
    "\n",
    "    # Estimation of average milk production during heat stress\n",
    "    average_production_heat_stress = y_pred.mean()\n",
    "    print(f\"Estimated average milk production during heat stress: {average_production_heat_stress:.4f}\")\n",
    "\n",
    "    # Calculate the reduction compared to baseline\n",
    "    reduction_percentage = ((baseline_mean - average_production_heat_stress) / baseline_mean) * 100\n",
    "    print(f\"Reduction in milk production during heat stress: {reduction_percentage:.2f}%\")\n",
    "\n",
    "    return average_production_heat_stress, reduction_percentage\n",
    "\n",
    "# Train the model with the feature combinations on the training set and print results\n",
    "for features in feature_combinations:\n",
    "    avg_prod_heatstress, reduction = fit_xgboost_and_print_results(train_heatstress, test_heatstress, features, baseline_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>Relative Change HeatStress = 1 (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>7.164465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FarmName_Pseudo  Relative Change HeatStress = 1 (%)\n",
       "0        a624fb9a                            7.164465"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'FarmName_Pseudo': pd.Series(dtype='object'),\n",
    "    'Relative Change HeatStress = 1 (%)': pd.Series(dtype='float64'),\n",
    "})\n",
    "\n",
    "# Create a new DataFrame row\n",
    "new_row = pd.DataFrame({\n",
    "    'FarmName_Pseudo': [farm_id],\n",
    "    'Relative Change HeatStress = 1 (%)': [reduction],\n",
    "})\n",
    "\n",
    "# Append the new row to the results DataFrame using pd.concat\n",
    "results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline mean of NormalizedDailyYield for all days: 0.9960\n",
      "\n",
      "Selected features: ['MeanTemperature', 'HW']\n",
      "Best parameters: {'lambda': 2.8128333149473076e-06, 'alpha': 0.046464638549997245, 'subsample': 0.6383000195343301, 'colsample_bytree': 0.5006066419952546, 'learning_rate': 0.08375819308322532, 'n_estimators': 423, 'max_depth': 8}\n",
      "Final model performance: MSE = 0.0364 ± 0.0014\n",
      "Mean Squared Error on test set: 0.0342\n",
      "Estimated average milk production during heat stress: 0.7857\n",
      "Reduction in milk production during heat stress: 21.11%\n",
      "\n",
      "Selected features: ['MeanTemperature', 'cum_HW']\n",
      "Best parameters: {'lambda': 5.761831914549366e-05, 'alpha': 6.780267615584031e-06, 'subsample': 0.8635616113669007, 'colsample_bytree': 0.6182321028951115, 'learning_rate': 0.0944408367530121, 'n_estimators': 536, 'max_depth': 5}\n",
      "Final model performance: MSE = 0.0364 ± 0.0014\n",
      "Mean Squared Error on test set: 0.0341\n",
      "Estimated average milk production during heat stress: 0.7862\n",
      "Reduction in milk production during heat stress: 21.06%\n",
      "\n",
      "Selected features: ['MeanTHI_adj', 'HW']\n",
      "Best parameters: {'lambda': 0.00017118930982881503, 'alpha': 0.00010205914109800406, 'subsample': 0.6184947002453394, 'colsample_bytree': 0.7671328495942356, 'learning_rate': 0.07508441936681322, 'n_estimators': 239, 'max_depth': 15}\n",
      "Final model performance: MSE = 0.0364 ± 0.0014\n",
      "Mean Squared Error on test set: 0.0342\n",
      "Estimated average milk production during heat stress: 0.7859\n",
      "Reduction in milk production during heat stress: 21.09%\n",
      "\n",
      "Selected features: ['MeanTHI_adj', 'cum_HW']\n",
      "Best parameters: {'lambda': 2.2871397918999193e-08, 'alpha': 2.2524947353981185e-05, 'subsample': 0.9499632599483635, 'colsample_bytree': 0.5184489489058671, 'learning_rate': 0.060311962923070374, 'n_estimators': 589, 'max_depth': 8}\n",
      "Final model performance: MSE = 0.0364 ± 0.0014\n",
      "Mean Squared Error on test set: 0.0342\n",
      "Estimated average milk production during heat stress: 0.7860\n",
      "Reduction in milk production during heat stress: 21.09%\n"
     ]
    }
   ],
   "source": [
    "# Specify the farm ID for analysis\n",
    "farm_id = '5c06d92d'\n",
    "\n",
    "# Filter data for the specific farm\n",
    "farm_data = milk_data[milk_data['FarmName_Pseudo'] == farm_id]\n",
    "\n",
    "# Calculate the baseline (mean of NormalizedDailyYield for all days at the farm)\n",
    "baseline_mean = farm_data['NormalizedDailyYield'].mean()\n",
    "print(f\"Baseline mean of NormalizedDailyYield for all days: {baseline_mean:.4f}\")\n",
    "\n",
    "# Define the feature combinations\n",
    "feature_combinations = [\n",
    "    ['MeanTemperature', 'HW'],\n",
    "    ['MeanTemperature', 'cum_HW'],\n",
    "    ['MeanTHI_adj', 'HW'],\n",
    "    ['MeanTHI_adj', 'cum_HW']\n",
    "]\n",
    "\n",
    "# Define target variable\n",
    "target = 'NormalizedDailyYield'\n",
    "\n",
    "# Filter data for heat stress conditions\n",
    "data_heatstress = farm_data[farm_data['HeatStress'] == 1]\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_heatstress, test_heatstress = train_test_split(data_heatstress, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the continuous features (MeanTemperature and MeanTHI_adj)\n",
    "scaler = StandardScaler()\n",
    "train_heatstress[['MeanTemperature', 'MeanTHI_adj']] = scaler.fit_transform(train_heatstress[['MeanTemperature', 'MeanTHI_adj']])\n",
    "test_heatstress[['MeanTemperature', 'MeanTHI_adj']] = scaler.transform(test_heatstress[['MeanTemperature', 'MeanTHI_adj']])\n",
    "\n",
    "# Function to optimize hyperparameters using Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'verbosity': 0,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 15),\n",
    "    }\n",
    "\n",
    "    # Cross-validation to estimate performance\n",
    "    model = xgb.XGBRegressor(**param)\n",
    "    scores = cross_val_score(model, train_heatstress[features], train_heatstress[target], cv=5, scoring='neg_mean_squared_error')\n",
    "    mse = -scores.mean()\n",
    "    return mse\n",
    "\n",
    "# Function to fit the model and print results\n",
    "def fit_xgboost_and_print_results(train_data, test_data, features, baseline_mean):\n",
    "    print(f\"\\nSelected features: {features}\")\n",
    "\n",
    "    # Optimize hyperparameters using Optuna (Bayesian Optimization)\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "    best_params = study.best_params\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "    # Train final model using the best parameters\n",
    "    best_model = xgb.XGBRegressor(**best_params)\n",
    "    best_model.fit(train_data[features], train_data[target])\n",
    "\n",
    "    # K-Fold Cross-Validation for final model evaluation\n",
    "    final_scores = cross_val_score(best_model, train_data[features], train_data[target], cv=5, scoring='neg_mean_squared_error')\n",
    "    final_mse = -final_scores.mean()\n",
    "    final_std = final_scores.std()\n",
    "    print(f\"Final model performance: MSE = {final_mse:.4f} ± {final_std:.4f}\")\n",
    "\n",
    "    # Predictions and evaluation on the test set\n",
    "    y_pred = best_model.predict(test_data[features])\n",
    "    mse = mean_squared_error(test_data[target], y_pred)\n",
    "    print(f\"Mean Squared Error on test set: {mse:.4f}\")\n",
    "\n",
    "    # Estimation of average milk production during heat stress\n",
    "    average_production_heat_stress = y_pred.mean()\n",
    "    print(f\"Estimated average milk production during heat stress: {average_production_heat_stress:.4f}\")\n",
    "\n",
    "    # Calculate the reduction compared to baseline\n",
    "    reduction_percentage = ((baseline_mean - average_production_heat_stress) / baseline_mean) * 100\n",
    "    print(f\"Reduction in milk production during heat stress: {reduction_percentage:.2f}%\")\n",
    "\n",
    "    return average_production_heat_stress, reduction_percentage\n",
    "\n",
    "# Train the model with the feature combinations on the training set and print results\n",
    "for features in feature_combinations:\n",
    "    avg_prod_heatstress, reduction = fit_xgboost_and_print_results(train_heatstress, test_heatstress, features, baseline_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>Relative Change HeatStress = 1 (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>7.164465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5c06d92d</td>\n",
       "      <td>21.085694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FarmName_Pseudo  Relative Change HeatStress = 1 (%)\n",
       "0        a624fb9a                            7.164465\n",
       "1        5c06d92d                           21.085694"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new DataFrame row\n",
    "new_row = pd.DataFrame({\n",
    "    'FarmName_Pseudo': [farm_id],\n",
    "    'Relative Change HeatStress = 1 (%)': [reduction],\n",
    "})\n",
    "\n",
    "# Append the new row to the results DataFrame using pd.concat\n",
    "results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline mean of NormalizedDailyYield for all days: 0.9936\n",
      "\n",
      "Selected features: ['MeanTemperature', 'HW']\n",
      "Best parameters: {'lambda': 2.5378409786854936e-07, 'alpha': 4.115993120233171e-07, 'subsample': 0.9016072329543205, 'colsample_bytree': 0.7883549212734269, 'learning_rate': 0.009465744237737056, 'n_estimators': 915, 'max_depth': 5}\n",
      "Final model performance: MSE = 0.0234 ± 0.0014\n",
      "Mean Squared Error on test set: 0.0276\n",
      "Estimated average milk production during heat stress: 0.8941\n",
      "Reduction in milk production during heat stress: 10.02%\n",
      "\n",
      "Selected features: ['MeanTemperature', 'cum_HW']\n",
      "Best parameters: {'lambda': 0.19430503014330436, 'alpha': 1.1827326300125545e-07, 'subsample': 0.706473570487271, 'colsample_bytree': 0.9749193029899594, 'learning_rate': 0.038890617901634845, 'n_estimators': 151, 'max_depth': 7}\n",
      "Final model performance: MSE = 0.0234 ± 0.0015\n",
      "Mean Squared Error on test set: 0.0276\n",
      "Estimated average milk production during heat stress: 0.8940\n",
      "Reduction in milk production during heat stress: 10.02%\n",
      "\n",
      "Selected features: ['MeanTHI_adj', 'HW']\n",
      "Best parameters: {'lambda': 3.604602367076861e-05, 'alpha': 0.0005115587643343998, 'subsample': 0.8222837662105597, 'colsample_bytree': 0.8462736024952646, 'learning_rate': 0.013222741437142945, 'n_estimators': 506, 'max_depth': 6}\n",
      "Final model performance: MSE = 0.0233 ± 0.0015\n",
      "Mean Squared Error on test set: 0.0273\n",
      "Estimated average milk production during heat stress: 0.8942\n",
      "Reduction in milk production during heat stress: 10.01%\n",
      "\n",
      "Selected features: ['MeanTHI_adj', 'cum_HW']\n",
      "Best parameters: {'lambda': 0.0011442526085824278, 'alpha': 0.006008447155656307, 'subsample': 0.5748781305134416, 'colsample_bytree': 0.7770513193661724, 'learning_rate': 0.020463942235144503, 'n_estimators': 354, 'max_depth': 6}\n",
      "Final model performance: MSE = 0.0233 ± 0.0015\n",
      "Mean Squared Error on test set: 0.0273\n",
      "Estimated average milk production during heat stress: 0.8940\n",
      "Reduction in milk production during heat stress: 10.03%\n"
     ]
    }
   ],
   "source": [
    "# Specify the farm ID for analysis\n",
    "farm_id = '752efd72'\n",
    "\n",
    "# Filter data for the specific farm\n",
    "farm_data = milk_data[milk_data['FarmName_Pseudo'] == farm_id]\n",
    "\n",
    "# Calculate the baseline (mean of NormalizedDailyYield for all days at the farm)\n",
    "baseline_mean = farm_data['NormalizedDailyYield'].mean()\n",
    "print(f\"Baseline mean of NormalizedDailyYield for all days: {baseline_mean:.4f}\")\n",
    "\n",
    "# Define the feature combinations\n",
    "feature_combinations = [\n",
    "    ['MeanTemperature', 'HW'],\n",
    "    ['MeanTemperature', 'cum_HW'],\n",
    "    ['MeanTHI_adj', 'HW'],\n",
    "    ['MeanTHI_adj', 'cum_HW']\n",
    "]\n",
    "\n",
    "# Define target variable\n",
    "target = 'NormalizedDailyYield'\n",
    "\n",
    "# Filter data for heat stress conditions\n",
    "data_heatstress = farm_data[farm_data['HeatStress'] == 1]\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_heatstress, test_heatstress = train_test_split(data_heatstress, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the continuous features (MeanTemperature and MeanTHI_adj)\n",
    "scaler = StandardScaler()\n",
    "train_heatstress[['MeanTemperature', 'MeanTHI_adj']] = scaler.fit_transform(train_heatstress[['MeanTemperature', 'MeanTHI_adj']])\n",
    "test_heatstress[['MeanTemperature', 'MeanTHI_adj']] = scaler.transform(test_heatstress[['MeanTemperature', 'MeanTHI_adj']])\n",
    "\n",
    "# Function to optimize hyperparameters using Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'verbosity': 0,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 15),\n",
    "    }\n",
    "\n",
    "    # Cross-validation to estimate performance\n",
    "    model = xgb.XGBRegressor(**param)\n",
    "    scores = cross_val_score(model, train_heatstress[features], train_heatstress[target], cv=5, scoring='neg_mean_squared_error')\n",
    "    mse = -scores.mean()\n",
    "    return mse\n",
    "\n",
    "# Function to fit the model and print results\n",
    "def fit_xgboost_and_print_results(train_data, test_data, features, baseline_mean):\n",
    "    print(f\"\\nSelected features: {features}\")\n",
    "\n",
    "    # Optimize hyperparameters using Optuna\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "    best_params = study.best_params\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "    # Train final model using the best parameters\n",
    "    best_model = xgb.XGBRegressor(**best_params)\n",
    "    best_model.fit(train_data[features], train_data[target])\n",
    "\n",
    "    # K-Fold Cross-Validation for final model evaluation\n",
    "    final_scores = cross_val_score(best_model, train_data[features], train_data[target], cv=5, scoring='neg_mean_squared_error')\n",
    "    final_mse = -final_scores.mean()\n",
    "    final_std = final_scores.std()\n",
    "    print(f\"Final model performance: MSE = {final_mse:.4f} ± {final_std:.4f}\")\n",
    "\n",
    "    # Predictions and evaluation on the test set\n",
    "    y_pred = best_model.predict(test_data[features])\n",
    "    mse = mean_squared_error(test_data[target], y_pred)\n",
    "    print(f\"Mean Squared Error on test set: {mse:.4f}\")\n",
    "\n",
    "    # Estimation of average milk production during heat stress\n",
    "    average_production_heat_stress = y_pred.mean()\n",
    "    print(f\"Estimated average milk production during heat stress: {average_production_heat_stress:.4f}\")\n",
    "\n",
    "    # Calculate the reduction compared to baseline\n",
    "    reduction_percentage = ((baseline_mean - average_production_heat_stress) / baseline_mean) * 100\n",
    "    print(f\"Reduction in milk production during heat stress: {reduction_percentage:.2f}%\")\n",
    "\n",
    "    return average_production_heat_stress, reduction_percentage\n",
    "\n",
    "# Train the model with the feature combinations on the training set and print results\n",
    "for features in feature_combinations:\n",
    "    avg_prod_heatstress, reduction = fit_xgboost_and_print_results(train_heatstress, test_heatstress, features, baseline_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>Relative Change HeatStress = 1 (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>7.164465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5c06d92d</td>\n",
       "      <td>21.085694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>752efd72</td>\n",
       "      <td>10.030104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FarmName_Pseudo  Relative Change HeatStress = 1 (%)\n",
       "0        a624fb9a                            7.164465\n",
       "1        5c06d92d                           21.085694\n",
       "2        752efd72                           10.030104"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new DataFrame row\n",
    "new_row = pd.DataFrame({\n",
    "    'FarmName_Pseudo': [farm_id],\n",
    "    'Relative Change HeatStress = 1 (%)': [reduction],\n",
    "})\n",
    "\n",
    "# Append the new row to the results DataFrame using pd.concat\n",
    "results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline mean of NormalizedDailyYield for all days: 0.9981\n",
      "\n",
      "Selected features: ['MeanTemperature', 'HW']\n",
      "Best parameters: {'lambda': 0.46284015147225926, 'alpha': 6.478223561589985e-08, 'subsample': 0.9600521035372284, 'colsample_bytree': 0.8380503210108585, 'learning_rate': 0.001911752665349074, 'n_estimators': 870, 'max_depth': 10}\n",
      "Final model performance: MSE = 0.0605 ± 0.0036\n",
      "Mean Squared Error on test set: 0.0606\n",
      "Estimated average milk production during heat stress: 0.9511\n",
      "Reduction in milk production during heat stress: 4.71%\n",
      "\n",
      "Selected features: ['MeanTemperature', 'cum_HW']\n",
      "Best parameters: {'lambda': 0.2256663498326168, 'alpha': 0.00023958171093556817, 'subsample': 0.9854525789899331, 'colsample_bytree': 0.9772673635650675, 'learning_rate': 0.002128098344781793, 'n_estimators': 742, 'max_depth': 11}\n",
      "Final model performance: MSE = 0.0605 ± 0.0036\n",
      "Mean Squared Error on test set: 0.0606\n",
      "Estimated average milk production during heat stress: 0.9512\n",
      "Reduction in milk production during heat stress: 4.71%\n",
      "\n",
      "Selected features: ['MeanTHI_adj', 'HW']\n",
      "Best parameters: {'lambda': 1.0033156118704933e-07, 'alpha': 2.822059720516777e-07, 'subsample': 0.8086733437674123, 'colsample_bytree': 0.5568561507823906, 'learning_rate': 0.0026294374559207435, 'n_estimators': 753, 'max_depth': 7}\n",
      "Final model performance: MSE = 0.0604 ± 0.0036\n",
      "Mean Squared Error on test set: 0.0605\n",
      "Estimated average milk production during heat stress: 0.9512\n",
      "Reduction in milk production during heat stress: 4.70%\n",
      "\n",
      "Selected features: ['MeanTHI_adj', 'cum_HW']\n",
      "Best parameters: {'lambda': 4.2046479587674196e-07, 'alpha': 0.0005835439393872082, 'subsample': 0.5169555155037782, 'colsample_bytree': 0.8181023760126553, 'learning_rate': 0.015010192027876557, 'n_estimators': 98, 'max_depth': 14}\n",
      "Final model performance: MSE = 0.0604 ± 0.0037\n",
      "Mean Squared Error on test set: 0.0605\n",
      "Estimated average milk production during heat stress: 0.9511\n",
      "Reduction in milk production during heat stress: 4.72%\n"
     ]
    }
   ],
   "source": [
    "# Specify the farm ID for analysis\n",
    "farm_id = 'f454e660'\n",
    "\n",
    "# Filter data for the specific farm\n",
    "farm_data = milk_data[milk_data['FarmName_Pseudo'] == farm_id]\n",
    "\n",
    "# Calculate the baseline (mean of NormalizedDailyYield for all days at the farm)\n",
    "baseline_mean = farm_data['NormalizedDailyYield'].mean()\n",
    "print(f\"Baseline mean of NormalizedDailyYield for all days: {baseline_mean:.4f}\")\n",
    "\n",
    "# Define the feature combinations\n",
    "feature_combinations = [\n",
    "    ['MeanTemperature', 'HW'],\n",
    "    ['MeanTemperature', 'cum_HW'],\n",
    "    ['MeanTHI_adj', 'HW'],\n",
    "    ['MeanTHI_adj', 'cum_HW']\n",
    "]\n",
    "\n",
    "# Define target variable\n",
    "target = 'NormalizedDailyYield'\n",
    "\n",
    "# Filter data for heat stress conditions\n",
    "data_heatstress = farm_data[farm_data['HeatStress'] == 1]\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_heatstress, test_heatstress = train_test_split(data_heatstress, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the continuous features (MeanTemperature and MeanTHI_adj)\n",
    "scaler = StandardScaler()\n",
    "train_heatstress[['MeanTemperature', 'MeanTHI_adj']] = scaler.fit_transform(train_heatstress[['MeanTemperature', 'MeanTHI_adj']])\n",
    "test_heatstress[['MeanTemperature', 'MeanTHI_adj']] = scaler.transform(test_heatstress[['MeanTemperature', 'MeanTHI_adj']])\n",
    "\n",
    "# Function to optimize hyperparameters using Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'verbosity': 0,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 15),\n",
    "    }\n",
    "\n",
    "    # Cross-validation to estimate performance\n",
    "    model = xgb.XGBRegressor(**param)\n",
    "    scores = cross_val_score(model, train_heatstress[features], train_heatstress[target], cv=5, scoring='neg_mean_squared_error')\n",
    "    mse = -scores.mean()\n",
    "    return mse\n",
    "\n",
    "# Function to fit the model and print results\n",
    "def fit_xgboost_and_print_results(train_data, test_data, features, baseline_mean):\n",
    "    print(f\"\\nSelected features: {features}\")\n",
    "\n",
    "    # Optimize hyperparameters using Optuna\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "    best_params = study.best_params\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "    # Train final model using the best parameters\n",
    "    best_model = xgb.XGBRegressor(**best_params)\n",
    "    best_model.fit(train_data[features], train_data[target])\n",
    "\n",
    "    # K-Fold Cross-Validation for final model evaluation\n",
    "    final_scores = cross_val_score(best_model, train_data[features], train_data[target], cv=5, scoring='neg_mean_squared_error')\n",
    "    final_mse = -final_scores.mean()\n",
    "    final_std = final_scores.std()\n",
    "    print(f\"Final model performance: MSE = {final_mse:.4f} ± {final_std:.4f}\")\n",
    "\n",
    "    # Predictions and evaluation on the test set\n",
    "    y_pred = best_model.predict(test_data[features])\n",
    "    mse = mean_squared_error(test_data[target], y_pred)\n",
    "    print(f\"Mean Squared Error on test set: {mse:.4f}\")\n",
    "\n",
    "    # Estimation of average milk production during heat stress\n",
    "    average_production_heat_stress = y_pred.mean()\n",
    "    print(f\"Estimated average milk production during heat stress: {average_production_heat_stress:.4f}\")\n",
    "\n",
    "    # Calculate the reduction compared to baseline\n",
    "    reduction_percentage = ((baseline_mean - average_production_heat_stress) / baseline_mean) * 100\n",
    "    print(f\"Reduction in milk production during heat stress: {reduction_percentage:.2f}%\")\n",
    "\n",
    "    return average_production_heat_stress, reduction_percentage\n",
    "\n",
    "# Train the model with the feature combinations on the training set and print results\n",
    "for features in feature_combinations:\n",
    "    avg_prod_heatstress, reduction = fit_xgboost_and_print_results(train_heatstress, test_heatstress, features, baseline_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>Relative Change HeatStress = 1 (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>7.164465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5c06d92d</td>\n",
       "      <td>21.085694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>752efd72</td>\n",
       "      <td>10.030104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f454e660</td>\n",
       "      <td>4.716855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FarmName_Pseudo  Relative Change HeatStress = 1 (%)\n",
       "0        a624fb9a                            7.164465\n",
       "1        5c06d92d                           21.085694\n",
       "2        752efd72                           10.030104\n",
       "3        f454e660                            4.716855"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new DataFrame row\n",
    "new_row = pd.DataFrame({\n",
    "    'FarmName_Pseudo': [farm_id],\n",
    "    'Relative Change HeatStress = 1 (%)': [reduction],\n",
    "})\n",
    "\n",
    "# Append the new row to the results DataFrame using pd.concat\n",
    "results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>Relative Change HeatStress = 1 (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>-7.164465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5c06d92d</td>\n",
       "      <td>-21.085694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>752efd72</td>\n",
       "      <td>-10.030104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f454e660</td>\n",
       "      <td>-4.716855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FarmName_Pseudo  Relative Change HeatStress = 1 (%)\n",
       "0        a624fb9a                           -7.164465\n",
       "1        5c06d92d                          -21.085694\n",
       "2        752efd72                          -10.030104\n",
       "3        f454e660                           -4.716855"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign a minus to the relative change for all reductions\n",
    "results_df['Relative Change HeatStress = 1 (%)'] = -results_df['Relative Change HeatStress = 1 (%)']\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert percentages to absolute changes (as per your requirement)\n",
    "results_df['Relative Change HeatStress = 1'] = results_df['Relative Change HeatStress = 1 (%)'] / 100\n",
    "\n",
    "# Create a dictionary for quick lookup\n",
    "heatstress_change_dict = {}\n",
    "for idx, row in results_df.iterrows():\n",
    "    heatstress_change_dict[(row['FarmName_Pseudo'], 1)] = row['Relative Change HeatStress = 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>SE_Number</th>\n",
       "      <th>Age</th>\n",
       "      <th>LactationNumber</th>\n",
       "      <th>DaysInMilk</th>\n",
       "      <th>YearSeason</th>\n",
       "      <th>DailyYield</th>\n",
       "      <th>PreviousDailyYield</th>\n",
       "      <th>DailyYieldChange</th>\n",
       "      <th>ExpectedYield</th>\n",
       "      <th>NormalizedDailyYield</th>\n",
       "      <th>NormalizedDailyYieldChange</th>\n",
       "      <th>HeatStress</th>\n",
       "      <th>Temp15Threshold</th>\n",
       "      <th>HW</th>\n",
       "      <th>cum_HW</th>\n",
       "      <th>MeanTemperature</th>\n",
       "      <th>MeanTHI_adj</th>\n",
       "      <th>FarmHeatStressMilkProduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>SE-064c0cec-1189</td>\n",
       "      <td>3095</td>\n",
       "      <td>7</td>\n",
       "      <td>191</td>\n",
       "      <td>2022-1</td>\n",
       "      <td>30.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.739372</td>\n",
       "      <td>1.034655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.025000</td>\n",
       "      <td>28.012944</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>SE-064c0cec-1189</td>\n",
       "      <td>3096</td>\n",
       "      <td>7</td>\n",
       "      <td>192</td>\n",
       "      <td>2022-1</td>\n",
       "      <td>48.22</td>\n",
       "      <td>30.77</td>\n",
       "      <td>17.45</td>\n",
       "      <td>29.692059</td>\n",
       "      <td>1.624003</td>\n",
       "      <td>0.587699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.279167</td>\n",
       "      <td>32.898193</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>SE-064c0cec-1189</td>\n",
       "      <td>3097</td>\n",
       "      <td>7</td>\n",
       "      <td>193</td>\n",
       "      <td>2022-1</td>\n",
       "      <td>30.53</td>\n",
       "      <td>48.22</td>\n",
       "      <td>-17.69</td>\n",
       "      <td>29.644756</td>\n",
       "      <td>1.029862</td>\n",
       "      <td>-0.596733</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>36.760487</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>SE-064c0cec-1189</td>\n",
       "      <td>3098</td>\n",
       "      <td>7</td>\n",
       "      <td>194</td>\n",
       "      <td>2022-1</td>\n",
       "      <td>42.26</td>\n",
       "      <td>30.53</td>\n",
       "      <td>11.73</td>\n",
       "      <td>29.597463</td>\n",
       "      <td>1.427825</td>\n",
       "      <td>0.396318</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>31.939524</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>SE-064c0cec-1189</td>\n",
       "      <td>3099</td>\n",
       "      <td>7</td>\n",
       "      <td>195</td>\n",
       "      <td>2022-1</td>\n",
       "      <td>38.49</td>\n",
       "      <td>42.26</td>\n",
       "      <td>-3.77</td>\n",
       "      <td>29.550181</td>\n",
       "      <td>1.302530</td>\n",
       "      <td>-0.127580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.700000</td>\n",
       "      <td>26.498206</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date FarmName_Pseudo         SE_Number   Age  LactationNumber  \\\n",
       "0 2022-01-01        a624fb9a  SE-064c0cec-1189  3095                7   \n",
       "1 2022-01-02        a624fb9a  SE-064c0cec-1189  3096                7   \n",
       "2 2022-01-03        a624fb9a  SE-064c0cec-1189  3097                7   \n",
       "3 2022-01-04        a624fb9a  SE-064c0cec-1189  3098                7   \n",
       "4 2022-01-05        a624fb9a  SE-064c0cec-1189  3099                7   \n",
       "\n",
       "   DaysInMilk YearSeason  DailyYield  PreviousDailyYield  DailyYieldChange  \\\n",
       "0         191     2022-1       30.77                0.00              0.00   \n",
       "1         192     2022-1       48.22               30.77             17.45   \n",
       "2         193     2022-1       30.53               48.22            -17.69   \n",
       "3         194     2022-1       42.26               30.53             11.73   \n",
       "4         195     2022-1       38.49               42.26             -3.77   \n",
       "\n",
       "   ExpectedYield  NormalizedDailyYield  NormalizedDailyYieldChange  \\\n",
       "0      29.739372              1.034655                    0.000000   \n",
       "1      29.692059              1.624003                    0.587699   \n",
       "2      29.644756              1.029862                   -0.596733   \n",
       "3      29.597463              1.427825                    0.396318   \n",
       "4      29.550181              1.302530                   -0.127580   \n",
       "\n",
       "   HeatStress  Temp15Threshold  HW  cum_HW  MeanTemperature  MeanTHI_adj  \\\n",
       "0           0                0   0       0        -3.025000    28.012944   \n",
       "1           0                0   0       0        -0.279167    32.898193   \n",
       "2           0                0   0       0         2.033333    36.760487   \n",
       "3           0                0   0       0         0.066667    31.939524   \n",
       "4           0                0   0       0        -3.700000    26.498206   \n",
       "\n",
       "   FarmHeatStressMilkProduction  \n",
       "0                           NaN  \n",
       "1                           NaN  \n",
       "2                           NaN  \n",
       "3                           NaN  \n",
       "4                           NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to assign the relative change based on FarmName_Pseudo and HeatStress\n",
    "def assign_relative_change(row):\n",
    "    if row['HeatStress'] == 1:\n",
    "        return heatstress_change_dict.get((row['FarmName_Pseudo'], 1), np.nan)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function to create the new column\n",
    "milk_data['FarmHeatStressMilkProduction'] = milk_data.apply(assign_relative_change, axis=1)\n",
    "\n",
    "# Display the first few rows to verify the changes\n",
    "milk_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new data to a new CSV file called 'XGBMilkFarmYieldData.csv' in same folder\n",
    "milk_data.to_csv('../Data/MergedData/XGBMilkFarmYieldData.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables Explanation for `XGBMilkFarmYieldData.csv`\n",
    "\n",
    "1. **Date**:\n",
    "   - Description: The date when the milk yield was recorded.\n",
    "   - Datatype: `datetime`\n",
    "   - Format: `YYYY-MM-DD`\n",
    "   - Example: `2022-01-01`\n",
    "\n",
    "2. **FarmName_Pseudo**:\n",
    "   - Description: A pseudo-identifier for the farm where the data was collected.\n",
    "   - Datatype: `str`\n",
    "   - Example: `a624fb9a`\n",
    "\n",
    "3. **SE_Number**:\n",
    "   - Description: A unique identifier for the cow, which has been formatted to include the farm and the animal number.\n",
    "   - Datatype: `str`\n",
    "   - Example: `SE-064c0cec-1189`\n",
    "\n",
    "4. **Age**:\n",
    "   - Description: The age of the cow in days.\n",
    "   - Datatype: `Int64`\n",
    "   - Example: `3095`\n",
    "\n",
    "5. **BreedName**:\n",
    "   - Description: The breed name of the cow.\n",
    "   - Datatype: `str`\n",
    "   - Example: `02 SLB`\n",
    "\n",
    "6. **LactationNumber**:\n",
    "   - Description: The number assigned to the cow's lactation cycle.\n",
    "   - Datatype: `Int64`\n",
    "   - Example: `7`\n",
    "\n",
    "7. **DaysInMilk**:\n",
    "   - Description: The number of days the cow has been in milk (lactating) at the time of recording.\n",
    "   - Datatype: `Int64`\n",
    "   - Example: `191`\n",
    "\n",
    "8. **YearSeason**:\n",
    "   - Description: The seasonal period based on the year and the month range.\n",
    "   - Datatype: `str`\n",
    "   - Example: `2022-1`\n",
    "   - YearSeason parameters in yield datasets:\n",
    "     - 1: Dec-Feb\n",
    "     - 2: Mar-May\n",
    "     - 3: Jun-Aug\n",
    "     - 4: Sep-Nov\n",
    "\n",
    "9. **DailyYield**:\n",
    "   - Description: The total amount of milk produced by the cow in a single day.\n",
    "   - Datatype: `float`\n",
    "   - Example: `30.77`\n",
    "\n",
    "10. **PreviousDailyYield**:\n",
    "    - Description: The total amount of milk produced by the cow on the previous day.\n",
    "    - Datatype: `float`\n",
    "    - Example: `0.0`\n",
    "\n",
    "11. **DailyYieldChange**:\n",
    "    - Description: The change in daily milk yield from the previous day.\n",
    "    - Datatype: `float`\n",
    "    - Example: `0.0`\n",
    "\n",
    "12. **ExpectedYield**:\n",
    "    - Description: The expected amount of milk yield based on certain models or predictions.\n",
    "    - Datatype: `float`\n",
    "    - Example: `35.914865`\n",
    "\n",
    "13. **NormalizedDailyYield**:\n",
    "    - Description: The daily yield normalized to account for various factors.\n",
    "    - Datatype: `float`\n",
    "    - Example: `0.856748`\n",
    "\n",
    "14. **NormalizedDailyYieldChange**:\n",
    "    - Description: The change in normalized daily yield from the previous day.\n",
    "    - Datatype: `float`\n",
    "    - Example: `0.0`\n",
    "\n",
    "15. **HeatStress**:\n",
    "    - Description: A binary variable indicating the presence of heat stress on the cow.\n",
    "    - Datatype: `Int64`\n",
    "    - Example: `0`\n",
    "\n",
    "16. **Temp15Threshold**:\n",
    "    - Description: A binary variable indicating if the temperature exceeded 15 degrees Celsius on the given day.\n",
    "    - Datatype: `Int64`\n",
    "    - Example: `0`\n",
    "\n",
    "17. **HW**:\n",
    "    - Description: A binary variable indicating the presence of a heatwave on the day.\n",
    "    - Datatype: `Int64`\n",
    "    - Example: `0`\n",
    "\n",
    "18. **cum_HW**:\n",
    "    - Description: Cumulative number of heatwave days up to the current date.\n",
    "    - Datatype: `Int64`\n",
    "    - Example: `0`\n",
    "\n",
    "19. **MeanTemperature**:\n",
    "    - Description: The mean temperature recorded on the day.\n",
    "    - Datatype: `float`\n",
    "    - Example: `-3.025`\n",
    "\n",
    "20. **MeanTHI_adj**:\n",
    "    - Description: The mean adjusted Temperature-Humidity Index for the day.\n",
    "    - Datatype: `float`\n",
    "    - Example: `28.012944`\n",
    "\n",
    "21. **FarmHeatStressMilkProduction**:\n",
    "    - Description: The relative change in milk production based on farm and heat stress conditions.\n",
    "    - Datatype: `float`\n",
    "    - Example: `0.009435`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GIGACOW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
