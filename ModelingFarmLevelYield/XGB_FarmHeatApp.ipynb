{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "# Set the Optuna logger to output only WARNING and higher levels\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set_context(\"notebook\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>SE_Number</th>\n",
       "      <th>Age</th>\n",
       "      <th>BreedName</th>\n",
       "      <th>LactationNumber</th>\n",
       "      <th>DaysInMilk</th>\n",
       "      <th>YearSeason</th>\n",
       "      <th>DailyYield</th>\n",
       "      <th>PreviousDailyYield</th>\n",
       "      <th>...</th>\n",
       "      <th>NormalizedDailyYieldChange</th>\n",
       "      <th>Residuals</th>\n",
       "      <th>HeatStress</th>\n",
       "      <th>Temp15Threshold</th>\n",
       "      <th>HW</th>\n",
       "      <th>cum_HW</th>\n",
       "      <th>MeanTemperature</th>\n",
       "      <th>MeanTHI_adj</th>\n",
       "      <th>HeatLoad</th>\n",
       "      <th>CumulativeHeatLoad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-28</td>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>SE-064c0cec-1189</td>\n",
       "      <td>3242</td>\n",
       "      <td>02 SLB</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-2</td>\n",
       "      <td>15.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.820438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.912500</td>\n",
       "      <td>50.478673</td>\n",
       "      <td>-10.521327</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-29</td>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>SE-064c0cec-1189</td>\n",
       "      <td>3243</td>\n",
       "      <td>02 SLB</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-2</td>\n",
       "      <td>18.96</td>\n",
       "      <td>15.22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215311</td>\n",
       "      <td>1.589745</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.066667</td>\n",
       "      <td>53.841648</td>\n",
       "      <td>-7.158352</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>SE-064c0cec-1189</td>\n",
       "      <td>3244</td>\n",
       "      <td>02 SLB</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-2</td>\n",
       "      <td>22.64</td>\n",
       "      <td>18.96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177389</td>\n",
       "      <td>1.894598</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.466667</td>\n",
       "      <td>52.935959</td>\n",
       "      <td>-8.064041</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>SE-064c0cec-1189</td>\n",
       "      <td>3245</td>\n",
       "      <td>02 SLB</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-2</td>\n",
       "      <td>26.49</td>\n",
       "      <td>22.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163049</td>\n",
       "      <td>2.877443</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.183333</td>\n",
       "      <td>52.872112</td>\n",
       "      <td>-8.127888</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>SE-064c0cec-1189</td>\n",
       "      <td>3246</td>\n",
       "      <td>02 SLB</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-3</td>\n",
       "      <td>33.61</td>\n",
       "      <td>26.49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273358</td>\n",
       "      <td>7.563598</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.704167</td>\n",
       "      <td>56.056547</td>\n",
       "      <td>-4.943453</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576066</th>\n",
       "      <td>2024-08-09</td>\n",
       "      <td>f454e660</td>\n",
       "      <td>SE-f454e660-810</td>\n",
       "      <td>1020</td>\n",
       "      <td>99 Korsning/obestämbar ras</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "      <td>2024-3</td>\n",
       "      <td>37.53</td>\n",
       "      <td>31.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168909</td>\n",
       "      <td>1.001508</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.650000</td>\n",
       "      <td>62.298109</td>\n",
       "      <td>1.298109</td>\n",
       "      <td>84.512273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576067</th>\n",
       "      <td>2024-08-10</td>\n",
       "      <td>f454e660</td>\n",
       "      <td>SE-f454e660-810</td>\n",
       "      <td>1021</td>\n",
       "      <td>99 Korsning/obestämbar ras</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "      <td>2024-3</td>\n",
       "      <td>36.48</td>\n",
       "      <td>37.53</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028745</td>\n",
       "      <td>-0.048492</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.308333</td>\n",
       "      <td>54.687773</td>\n",
       "      <td>-6.312227</td>\n",
       "      <td>71.887820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576068</th>\n",
       "      <td>2024-08-11</td>\n",
       "      <td>f454e660</td>\n",
       "      <td>SE-f454e660-810</td>\n",
       "      <td>1022</td>\n",
       "      <td>99 Korsning/obestämbar ras</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "      <td>2024-3</td>\n",
       "      <td>34.76</td>\n",
       "      <td>36.48</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047087</td>\n",
       "      <td>-1.768492</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.841667</td>\n",
       "      <td>55.974084</td>\n",
       "      <td>-5.025916</td>\n",
       "      <td>61.835988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576069</th>\n",
       "      <td>2024-08-12</td>\n",
       "      <td>f454e660</td>\n",
       "      <td>SE-f454e660-810</td>\n",
       "      <td>1023</td>\n",
       "      <td>99 Korsning/obestämbar ras</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "      <td>2024-3</td>\n",
       "      <td>38.06</td>\n",
       "      <td>34.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090340</td>\n",
       "      <td>1.531508</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.516667</td>\n",
       "      <td>60.115007</td>\n",
       "      <td>-0.884993</td>\n",
       "      <td>60.066002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576070</th>\n",
       "      <td>2024-08-13</td>\n",
       "      <td>f454e660</td>\n",
       "      <td>SE-f454e660-810</td>\n",
       "      <td>1024</td>\n",
       "      <td>99 Korsning/obestämbar ras</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "      <td>2024-3</td>\n",
       "      <td>34.96</td>\n",
       "      <td>38.06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084865</td>\n",
       "      <td>-1.568492</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.133333</td>\n",
       "      <td>65.856993</td>\n",
       "      <td>4.856993</td>\n",
       "      <td>64.922995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576071 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date FarmName_Pseudo         SE_Number   Age  \\\n",
       "0      2022-05-28        a624fb9a  SE-064c0cec-1189  3242   \n",
       "1      2022-05-29        a624fb9a  SE-064c0cec-1189  3243   \n",
       "2      2022-05-30        a624fb9a  SE-064c0cec-1189  3244   \n",
       "3      2022-05-31        a624fb9a  SE-064c0cec-1189  3245   \n",
       "4      2022-06-01        a624fb9a  SE-064c0cec-1189  3246   \n",
       "...           ...             ...               ...   ...   \n",
       "576066 2024-08-09        f454e660   SE-f454e660-810  1020   \n",
       "576067 2024-08-10        f454e660   SE-f454e660-810  1021   \n",
       "576068 2024-08-11        f454e660   SE-f454e660-810  1022   \n",
       "576069 2024-08-12        f454e660   SE-f454e660-810  1023   \n",
       "576070 2024-08-13        f454e660   SE-f454e660-810  1024   \n",
       "\n",
       "                         BreedName  LactationNumber  DaysInMilk YearSeason  \\\n",
       "0                           02 SLB                8           3     2022-2   \n",
       "1                           02 SLB                8           4     2022-2   \n",
       "2                           02 SLB                8           5     2022-2   \n",
       "3                           02 SLB                8           6     2022-2   \n",
       "4                           02 SLB                8           7     2022-3   \n",
       "...                            ...              ...         ...        ...   \n",
       "576066  99 Korsning/obestämbar ras                1         365     2024-3   \n",
       "576067  99 Korsning/obestämbar ras                1         365     2024-3   \n",
       "576068  99 Korsning/obestämbar ras                1         365     2024-3   \n",
       "576069  99 Korsning/obestämbar ras                1         365     2024-3   \n",
       "576070  99 Korsning/obestämbar ras                1         365     2024-3   \n",
       "\n",
       "        DailyYield  PreviousDailyYield  ...  NormalizedDailyYieldChange  \\\n",
       "0            15.22                 NaN  ...                         NaN   \n",
       "1            18.96               15.22  ...                    0.215311   \n",
       "2            22.64               18.96  ...                    0.177389   \n",
       "3            26.49               22.64  ...                    0.163049   \n",
       "4            33.61               26.49  ...                    0.273358   \n",
       "...            ...                 ...  ...                         ...   \n",
       "576066       37.53               31.36  ...                    0.168909   \n",
       "576067       36.48               37.53  ...                   -0.028745   \n",
       "576068       34.76               36.48  ...                   -0.047087   \n",
       "576069       38.06               34.76  ...                    0.090340   \n",
       "576070       34.96               38.06  ...                   -0.084865   \n",
       "\n",
       "        Residuals  HeatStress  Temp15Threshold  HW  cum_HW  MeanTemperature  \\\n",
       "0        1.820438           0                0   0       0         9.912500   \n",
       "1        1.589745           0                0   0       0        10.066667   \n",
       "2        1.894598           0                1   0       0        10.466667   \n",
       "3        2.877443           0                0   0       0        11.183333   \n",
       "4        7.563598           0                1   0       0        12.704167   \n",
       "...           ...         ...              ...  ..     ...              ...   \n",
       "576066   1.001508           1                1   0       0        18.650000   \n",
       "576067  -0.048492           1                1   0       0        18.308333   \n",
       "576068  -1.768492           1                1   0       0        17.841667   \n",
       "576069   1.531508           1                1   0       0        17.516667   \n",
       "576070  -1.568492           1                1   0       0        18.133333   \n",
       "\n",
       "        MeanTHI_adj   HeatLoad  CumulativeHeatLoad  \n",
       "0         50.478673 -10.521327            0.000000  \n",
       "1         53.841648  -7.158352            0.000000  \n",
       "2         52.935959  -8.064041            0.000000  \n",
       "3         52.872112  -8.127888            0.000000  \n",
       "4         56.056547  -4.943453            0.000000  \n",
       "...             ...        ...                 ...  \n",
       "576066    62.298109   1.298109           84.512273  \n",
       "576067    54.687773  -6.312227           71.887820  \n",
       "576068    55.974084  -5.025916           61.835988  \n",
       "576069    60.115007  -0.884993           60.066002  \n",
       "576070    65.856993   4.856993           64.922995  \n",
       "\n",
       "[576071 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype_dict = {\n",
    "    'Date': 'str',\n",
    "    'FarmName_Pseudo': 'str',\n",
    "    'SE_Number': 'str',\n",
    "    'Age': 'Int64',\n",
    "    'BreedName': 'str',\n",
    "    'DailyYield': 'float',\n",
    "    'PreviousDailyYield': 'float',\n",
    "    'DailyYieldChange': 'float',\n",
    "    'DaysInMilk': 'Int64',\n",
    "    'YearSeason': 'str',\n",
    "    'LactationNumber': 'Int64',\n",
    "    'ExpectedYield': 'float',\n",
    "    'NormalizedDailyYield': 'float',\n",
    "    'NormalizedDailyYieldChange': 'float',\n",
    "    'HeatStress': 'Int64',\n",
    "    'Temp15Threshold': 'Int64',\n",
    "    'HW': 'Int64',\n",
    "    'cum_HW': 'Int64',\n",
    "    'MeanTemperature': 'float',\n",
    "    'MeanTHI_adj': 'float',\n",
    "    'HeatLoad': 'float',\n",
    "    'CumulativeHeatLoad': 'float',\n",
    "}\n",
    "\n",
    "milk_data = pd.read_csv('../Data/MergedData/HeatApproachYieldDataTest.csv', dtype=dtype_dict)\n",
    "milk_data['Date'] = pd.to_datetime(milk_data['Date'], format='%Y-%m-%d')\n",
    "milk_data.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of NormalizedDailyYield: 1.0007464812391016\n",
      "Standard Deviation of NormalizedDailyYield: 0.17820337652716353\n",
      "Variance of NormalizedDailyYield: 0.03175644340568202\n",
      "\n",
      "Selected features: ['HeatStress']\n",
      "Best parameters: {'lambda': 0.034621477616408596, 'alpha': 0.0003778581621813498, 'subsample': 0.5209161179387255, 'colsample_bytree': 0.8726918083283083, 'learning_rate': 0.08538776303366605, 'n_estimators': 172, 'max_depth': 2}\n",
      "Estimated average production during heat stress: 0.9921\n",
      "Estimated average production without heat stress: 1.0034\n",
      "Reduction in milk production during heat stress: -0.0114\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>FarmHeatStressProduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>-0.011362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FarmName_Pseudo  FarmHeatStressProduction\n",
       "0        a624fb9a                 -0.011362"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=['FarmName_Pseudo', 'FarmHeatStressProduction'])\n",
    "\n",
    "# Specify the farm ID for analysis\n",
    "farm_id = 'a624fb9a'\n",
    "\n",
    "# Filter data for the specific farm\n",
    "farm_data = milk_data[milk_data['FarmName_Pseudo'] == farm_id]\n",
    "\n",
    "# Check if NormalizedDailyYield is centered around 1\n",
    "normalized_mean = farm_data['NormalizedDailyYield'].mean()\n",
    "normalized_variance = farm_data['NormalizedDailyYield'].var()\n",
    "print(\"Mean of NormalizedDailyYield:\", normalized_mean)\n",
    "print(\"Standard Deviation of NormalizedDailyYield:\", farm_data['NormalizedDailyYield'].std())\n",
    "print(\"Variance of NormalizedDailyYield:\", normalized_variance)\n",
    "\n",
    "# Define the target variable\n",
    "target = 'NormalizedDailyYield'\n",
    "\n",
    "# Split the data into train and validation sets\n",
    "train_data, val_data = train_test_split(farm_data, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the single feature\n",
    "features = ['HeatStress']\n",
    "\n",
    "# Function to optimize hyperparameters using Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'verbosity': 0,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 15),\n",
    "    }\n",
    "\n",
    "    # Cross-validation to estimate performance\n",
    "    model = xgb.XGBRegressor(**param)\n",
    "    scores = cross_val_score(model, train_data[features], train_data[target], cv=5, scoring='neg_mean_squared_error')\n",
    "    mse = -scores.mean()\n",
    "    return mse\n",
    "\n",
    "# Function to fit the model and calculate reduction due to HeatStress\n",
    "def fit_xgboost_and_calculate_reduction(train_data, val_data, features, baseline_mean):\n",
    "    print(f\"\\nSelected features: {features}\")\n",
    "\n",
    "    # Optimize hyperparameters using Optuna\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "    best_params = study.best_params\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "    # Train final model using the best parameters\n",
    "    best_model = xgb.XGBRegressor(**best_params)\n",
    "    best_model.fit(train_data[features], train_data[target])\n",
    "\n",
    "    # Predict the NormalizedDailyYield under heat stress (HeatStress = 1)\n",
    "    val_data_heatstress = val_data.copy()\n",
    "    val_data_heatstress['HeatStress'] = 1\n",
    "    y_pred_heatstress = best_model.predict(val_data_heatstress[features])\n",
    "    avg_production_heatstress = y_pred_heatstress.mean()\n",
    "\n",
    "    # Predict the NormalizedDailyYield without heat stress (HeatStress = 0)\n",
    "    val_data_no_heatstress = val_data.copy()\n",
    "    val_data_no_heatstress['HeatStress'] = 0\n",
    "    y_pred_no_heatstress = best_model.predict(val_data_no_heatstress[features])\n",
    "    avg_production_no_heatstress = y_pred_no_heatstress.mean()\n",
    "\n",
    "    # Calculate the reduction due to heat stress\n",
    "    reduction_due_to_heatstress = avg_production_heatstress - avg_production_no_heatstress\n",
    "\n",
    "    print(f\"Estimated average production during heat stress: {avg_production_heatstress:.4f}\")\n",
    "    print(f\"Estimated average production without heat stress: {avg_production_no_heatstress:.4f}\")\n",
    "    print(f\"Reduction in milk production during heat stress: {reduction_due_to_heatstress:.4f}\")\n",
    "\n",
    "    return reduction_due_to_heatstress\n",
    "\n",
    "# Train the model and calculate the reduction\n",
    "reduction = fit_xgboost_and_calculate_reduction(train_data, val_data, features, normalized_mean)\n",
    "\n",
    "# Create a new DataFrame for the current farm's result\n",
    "new_result = pd.DataFrame([{\n",
    "    'FarmName_Pseudo': farm_id,\n",
    "    'FarmHeatStressProduction': reduction\n",
    "}])\n",
    "\n",
    "# Check if results_df is empty before concatenation\n",
    "if results_df.empty:\n",
    "    results_df = new_result\n",
    "else:\n",
    "    results_df = pd.concat([results_df, new_result], ignore_index=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of NormalizedDailyYield: 1.0013067878458104\n",
      "Standard Deviation of NormalizedDailyYield: 0.13131819898745473\n",
      "Variance of NormalizedDailyYield: 0.017244469385308756\n",
      "\n",
      "Selected features: ['HeatStress']\n",
      "Best parameters: {'lambda': 0.015423882119563461, 'alpha': 0.0005831465692192785, 'subsample': 0.6857847052473738, 'colsample_bytree': 0.6441870107346002, 'learning_rate': 0.0966514851726896, 'n_estimators': 642, 'max_depth': 10}\n",
      "Estimated average production during heat stress: 0.9967\n",
      "Estimated average production without heat stress: 1.0027\n",
      "Reduction in milk production during heat stress: -0.0060\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>FarmHeatStressProduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>-0.011362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5c06d92d</td>\n",
       "      <td>-0.005975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FarmName_Pseudo  FarmHeatStressProduction\n",
       "0        a624fb9a                 -0.011362\n",
       "1        5c06d92d                 -0.005975"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the farm ID for analysis\n",
    "farm_id = '5c06d92d'\n",
    "\n",
    "# Filter data for the specific farm\n",
    "farm_data = milk_data[milk_data['FarmName_Pseudo'] == farm_id]\n",
    "\n",
    "# Check if NormalizedDailyYield is centered around 1\n",
    "normalized_mean = farm_data['NormalizedDailyYield'].mean()\n",
    "normalized_variance = farm_data['NormalizedDailyYield'].var()\n",
    "print(\"Mean of NormalizedDailyYield:\", normalized_mean)\n",
    "print(\"Standard Deviation of NormalizedDailyYield:\", farm_data['NormalizedDailyYield'].std())\n",
    "print(\"Variance of NormalizedDailyYield:\", normalized_variance)\n",
    "\n",
    "# Define the target variable\n",
    "target = 'NormalizedDailyYield'\n",
    "\n",
    "# Split the data into train and validation sets\n",
    "train_data, val_data = train_test_split(farm_data, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the single feature\n",
    "features = ['HeatStress']\n",
    "\n",
    "# Function to optimize hyperparameters using Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'verbosity': 0,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 15),\n",
    "    }\n",
    "\n",
    "    # Cross-validation to estimate performance\n",
    "    model = xgb.XGBRegressor(**param)\n",
    "    scores = cross_val_score(model, train_data[features], train_data[target], cv=5, scoring='neg_mean_squared_error')\n",
    "    mse = -scores.mean()\n",
    "    return mse\n",
    "\n",
    "# Function to fit the model and calculate reduction due to HeatStress\n",
    "def fit_xgboost_and_calculate_reduction(train_data, val_data, features, baseline_mean):\n",
    "    print(f\"\\nSelected features: {features}\")\n",
    "\n",
    "    # Optimize hyperparameters using Optuna\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "    best_params = study.best_params\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "    # Train final model using the best parameters\n",
    "    best_model = xgb.XGBRegressor(**best_params)\n",
    "    best_model.fit(train_data[features], train_data[target])\n",
    "\n",
    "    # Predict the NormalizedDailyYield under heat stress (HeatStress = 1)\n",
    "    val_data_heatstress = val_data.copy()\n",
    "    val_data_heatstress['HeatStress'] = 1\n",
    "    y_pred_heatstress = best_model.predict(val_data_heatstress[features])\n",
    "    avg_production_heatstress = y_pred_heatstress.mean()\n",
    "\n",
    "    # Predict the NormalizedDailyYield without heat stress (HeatStress = 0)\n",
    "    val_data_no_heatstress = val_data.copy()\n",
    "    val_data_no_heatstress['HeatStress'] = 0\n",
    "    y_pred_no_heatstress = best_model.predict(val_data_no_heatstress[features])\n",
    "    avg_production_no_heatstress = y_pred_no_heatstress.mean()\n",
    "\n",
    "    # Calculate the reduction due to heat stress\n",
    "    reduction_due_to_heatstress = avg_production_heatstress - avg_production_no_heatstress\n",
    "\n",
    "    print(f\"Estimated average production during heat stress: {avg_production_heatstress:.4f}\")\n",
    "    print(f\"Estimated average production without heat stress: {avg_production_no_heatstress:.4f}\")\n",
    "    print(f\"Reduction in milk production during heat stress: {reduction_due_to_heatstress:.4f}\")\n",
    "\n",
    "    return reduction_due_to_heatstress\n",
    "\n",
    "# Train the model and calculate the reduction\n",
    "reduction = fit_xgboost_and_calculate_reduction(train_data, val_data, features, normalized_mean)\n",
    "\n",
    "# Create a new DataFrame for the current farm's result\n",
    "new_result = pd.DataFrame([{\n",
    "    'FarmName_Pseudo': farm_id,\n",
    "    'FarmHeatStressProduction': reduction\n",
    "}])\n",
    "\n",
    "# Check if results_df is empty before concatenation\n",
    "if results_df.empty:\n",
    "    results_df = new_result\n",
    "else:\n",
    "    results_df = pd.concat([results_df, new_result], ignore_index=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of NormalizedDailyYield: 1.0015880766895515\n",
      "Standard Deviation of NormalizedDailyYield: 0.1030289029037514\n",
      "Variance of NormalizedDailyYield: 0.010614954833550634\n",
      "\n",
      "Selected features: ['HeatStress']\n",
      "Best parameters: {'lambda': 0.006260847829823792, 'alpha': 0.00013187927661273085, 'subsample': 0.5191754735316721, 'colsample_bytree': 0.9542751717099657, 'learning_rate': 0.059265766776770014, 'n_estimators': 623, 'max_depth': 6}\n",
      "Estimated average production during heat stress: 0.9933\n",
      "Estimated average production without heat stress: 1.0048\n",
      "Reduction in milk production during heat stress: -0.0115\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FarmName_Pseudo</th>\n",
       "      <th>FarmHeatStressProduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a624fb9a</td>\n",
       "      <td>-0.011362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5c06d92d</td>\n",
       "      <td>-0.005975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>752efd72</td>\n",
       "      <td>-0.011452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FarmName_Pseudo  FarmHeatStressProduction\n",
       "0        a624fb9a                 -0.011362\n",
       "1        5c06d92d                 -0.005975\n",
       "2        752efd72                 -0.011452"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the farm ID for analysis\n",
    "farm_id = '752efd72'\n",
    "\n",
    "# Filter data for the specific farm\n",
    "farm_data = milk_data[milk_data['FarmName_Pseudo'] == farm_id]\n",
    "\n",
    "# Check if NormalizedDailyYield is centered around 1\n",
    "normalized_mean = farm_data['NormalizedDailyYield'].mean()\n",
    "normalized_variance = farm_data['NormalizedDailyYield'].var()\n",
    "print(\"Mean of NormalizedDailyYield:\", normalized_mean)\n",
    "print(\"Standard Deviation of NormalizedDailyYield:\", farm_data['NormalizedDailyYield'].std())\n",
    "print(\"Variance of NormalizedDailyYield:\", normalized_variance)\n",
    "\n",
    "# Define the target variable\n",
    "target = 'NormalizedDailyYield'\n",
    "\n",
    "# Split the data into train and validation sets\n",
    "train_data, val_data = train_test_split(farm_data, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the single feature\n",
    "features = ['HeatStress']\n",
    "\n",
    "# Function to optimize hyperparameters using Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'verbosity': 0,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 15),\n",
    "    }\n",
    "\n",
    "    # Cross-validation to estimate performance\n",
    "    model = xgb.XGBRegressor(**param)\n",
    "    scores = cross_val_score(model, train_data[features], train_data[target], cv=5, scoring='neg_mean_squared_error')\n",
    "    mse = -scores.mean()\n",
    "    return mse\n",
    "\n",
    "# Function to fit the model and calculate reduction due to HeatStress\n",
    "def fit_xgboost_and_calculate_reduction(train_data, val_data, features, baseline_mean):\n",
    "    print(f\"\\nSelected features: {features}\")\n",
    "\n",
    "    # Optimize hyperparameters using Optuna\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "    best_params = study.best_params\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "    # Train final model using the best parameters\n",
    "    best_model = xgb.XGBRegressor(**best_params)\n",
    "    best_model.fit(train_data[features], train_data[target])\n",
    "\n",
    "    # Predict the NormalizedDailyYield under heat stress (HeatStress = 1)\n",
    "    val_data_heatstress = val_data.copy()\n",
    "    val_data_heatstress['HeatStress'] = 1\n",
    "    y_pred_heatstress = best_model.predict(val_data_heatstress[features])\n",
    "    avg_production_heatstress = y_pred_heatstress.mean()\n",
    "\n",
    "    # Predict the NormalizedDailyYield without heat stress (HeatStress = 0)\n",
    "    val_data_no_heatstress = val_data.copy()\n",
    "    val_data_no_heatstress['HeatStress'] = 0\n",
    "    y_pred_no_heatstress = best_model.predict(val_data_no_heatstress[features])\n",
    "    avg_production_no_heatstress = y_pred_no_heatstress.mean()\n",
    "\n",
    "    # Calculate the reduction due to heat stress\n",
    "    reduction_due_to_heatstress = avg_production_heatstress - avg_production_no_heatstress\n",
    "\n",
    "    print(f\"Estimated average production during heat stress: {avg_production_heatstress:.4f}\")\n",
    "    print(f\"Estimated average production without heat stress: {avg_production_no_heatstress:.4f}\")\n",
    "    print(f\"Reduction in milk production during heat stress: {reduction_due_to_heatstress:.4f}\")\n",
    "\n",
    "    return reduction_due_to_heatstress\n",
    "\n",
    "# Train the model and calculate the reduction\n",
    "reduction = fit_xgboost_and_calculate_reduction(train_data, val_data, features, normalized_mean)\n",
    "\n",
    "# Create a new DataFrame for the current farm's result\n",
    "new_result = pd.DataFrame([{\n",
    "    'FarmName_Pseudo': farm_id,\n",
    "    'FarmHeatStressProduction': reduction\n",
    "}])\n",
    "\n",
    "# Check if results_df is empty before concatenation\n",
    "if results_df.empty:\n",
    "    results_df = new_result\n",
    "else:\n",
    "    results_df = pd.concat([results_df, new_result], ignore_index=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of NormalizedDailyYield: 1.001072448009299\n",
      "Standard Deviation of NormalizedDailyYield: 0.2353243709243429\n",
      "Variance of NormalizedDailyYield: 0.05537755955093773\n",
      "\n",
      "Selected features: ['HeatStress']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-09-05 10:16:00,667] Trial 62 failed with parameters: {'lambda': 3.298173019519372e-05, 'alpha': 1.1209367157573246e-05, 'subsample': 0.8013585824119855, 'colsample_bytree': 0.9671582576044206, 'learning_rate': 0.07974410134560793, 'n_estimators': 853, 'max_depth': 15} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/n0/fphw_xw93vv749r_ntt01qd80000gn/T/ipykernel_29764/137233681.py\", line 39, in objective\n",
      "    scores = cross_val_score(model, train_data[features], train_data[target], cv=5, scoring='neg_mean_squared_error')\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 712, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "                 ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 423, in cross_validate\n",
      "    results = parallel(\n",
      "              ^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 67, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 129, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/user/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/xgboost/core.py\", line 2051, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2024-09-05 10:16:00,679] Trial 62 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 79\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reduction_due_to_heatstress\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Train the model and calculate the reduction\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m reduction \u001b[38;5;241m=\u001b[39m \u001b[43mfit_xgboost_and_calculate_reduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_mean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Create a new DataFrame for the current farm's result\u001b[39;00m\n\u001b[1;32m     82\u001b[0m new_result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([{\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFarmName_Pseudo\u001b[39m\u001b[38;5;124m'\u001b[39m: farm_id,\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFarmHeatStressProduction\u001b[39m\u001b[38;5;124m'\u001b[39m: reduction\n\u001b[1;32m     85\u001b[0m }])\n",
      "Cell \u001b[0;32mIn[6], line 49\u001b[0m, in \u001b[0;36mfit_xgboost_and_calculate_reduction\u001b[0;34m(train_data, val_data, features, baseline_mean)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Optimize hyperparameters using Optuna\u001b[39;00m\n\u001b[1;32m     48\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[6], line 39\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Cross-validation to estimate performance\u001b[39;00m\n\u001b[1;32m     38\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparam)\n\u001b[0;32m---> 39\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneg_mean_squared_error\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m mse \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mscores\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mse\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:423\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 423\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/xgboost/sklearn.py:1090\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m (\n\u001b[1;32m   1082\u001b[0m     model,\n\u001b[1;32m   1083\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1088\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1089\u001b[0m )\n\u001b[0;32m-> 1090\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GIGACOW/lib/python3.11/site-packages/xgboost/core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m     _check_call(\n\u001b[0;32m-> 2051\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2054\u001b[0m     )\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Specify the farm ID for analysis\n",
    "farm_id = 'f454e660'\n",
    "\n",
    "# Filter data for the specific farm\n",
    "farm_data = milk_data[milk_data['FarmName_Pseudo'] == farm_id]\n",
    "\n",
    "# Check if NormalizedDailyYield is centered around 1\n",
    "normalized_mean = farm_data['NormalizedDailyYield'].mean()\n",
    "normalized_variance = farm_data['NormalizedDailyYield'].var()\n",
    "print(\"Mean of NormalizedDailyYield:\", normalized_mean)\n",
    "print(\"Standard Deviation of NormalizedDailyYield:\", farm_data['NormalizedDailyYield'].std())\n",
    "print(\"Variance of NormalizedDailyYield:\", normalized_variance)\n",
    "\n",
    "# Define the target variable\n",
    "target = 'NormalizedDailyYield'\n",
    "\n",
    "# Split the data into train and validation sets\n",
    "train_data, val_data = train_test_split(farm_data, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the single feature\n",
    "features = ['HeatStress']\n",
    "\n",
    "# Function to optimize hyperparameters using Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'verbosity': 0,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 15),\n",
    "    }\n",
    "\n",
    "    # Cross-validation to estimate performance\n",
    "    model = xgb.XGBRegressor(**param)\n",
    "    scores = cross_val_score(model, train_data[features], train_data[target], cv=5, scoring='neg_mean_squared_error')\n",
    "    mse = -scores.mean()\n",
    "    return mse\n",
    "\n",
    "# Function to fit the model and calculate reduction due to HeatStress\n",
    "def fit_xgboost_and_calculate_reduction(train_data, val_data, features, baseline_mean):\n",
    "    print(f\"\\nSelected features: {features}\")\n",
    "\n",
    "    # Optimize hyperparameters using Optuna\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "    best_params = study.best_params\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "    # Train final model using the best parameters\n",
    "    best_model = xgb.XGBRegressor(**best_params)\n",
    "    best_model.fit(train_data[features], train_data[target])\n",
    "\n",
    "    # Predict the NormalizedDailyYield under heat stress (HeatStress = 1)\n",
    "    val_data_heatstress = val_data.copy()\n",
    "    val_data_heatstress['HeatStress'] = 1\n",
    "    y_pred_heatstress = best_model.predict(val_data_heatstress[features])\n",
    "    avg_production_heatstress = y_pred_heatstress.mean()\n",
    "\n",
    "    # Predict the NormalizedDailyYield without heat stress (HeatStress = 0)\n",
    "    val_data_no_heatstress = val_data.copy()\n",
    "    val_data_no_heatstress['HeatStress'] = 0\n",
    "    y_pred_no_heatstress = best_model.predict(val_data_no_heatstress[features])\n",
    "    avg_production_no_heatstress = y_pred_no_heatstress.mean()\n",
    "\n",
    "    # Calculate the reduction due to heat stress\n",
    "    reduction_due_to_heatstress = avg_production_heatstress - avg_production_no_heatstress\n",
    "\n",
    "    print(f\"Estimated average production during heat stress: {avg_production_heatstress:.4f}\")\n",
    "    print(f\"Estimated average production without heat stress: {avg_production_no_heatstress:.4f}\")\n",
    "    print(f\"Reduction in milk production during heat stress: {reduction_due_to_heatstress:.4f}\")\n",
    "\n",
    "    return reduction_due_to_heatstress\n",
    "\n",
    "# Train the model and calculate the reduction\n",
    "reduction = fit_xgboost_and_calculate_reduction(train_data, val_data, features, normalized_mean)\n",
    "\n",
    "# Create a new DataFrame for the current farm's result\n",
    "new_result = pd.DataFrame([{\n",
    "    'FarmName_Pseudo': farm_id,\n",
    "    'FarmHeatStressProduction': reduction\n",
    "}])\n",
    "\n",
    "# Check if results_df is empty before concatenation\n",
    "if results_df.empty:\n",
    "    results_df = new_result\n",
    "else:\n",
    "    results_df = pd.concat([results_df, new_result], ignore_index=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the results_df with milk_data on 'FarmName_Pseudo'\n",
    "milk_data = milk_data.merge(results_df, on='FarmName_Pseudo', how='left')\n",
    "\n",
    "# Set 'FarmHeatStressProduction' to NaN where 'HeatStress' is 0\n",
    "milk_data.loc[milk_data['HeatStress'] == 0, 'FarmHeatStressProduction'] = np.nan\n",
    "milk_data.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new data to a new CSV file called 'XGBMilkFarmYieldData.csv' in same folder\n",
    "milk_data.to_csv('../Data/MergedData/XGBHeatFarmYieldData.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables Explanation for `XGBHeatFarmYieldData.csv`\n",
    "\n",
    "1. **Date**:\n",
    "   - Description: The date when the milk yield was recorded.\n",
    "   - Datatype: `datetime`\n",
    "   - Format: `YYYY-MM-DD`\n",
    "   - Example: `2022-01-01`\n",
    "\n",
    "2. **FarmName_Pseudo**:\n",
    "   - Description: A pseudo-identifier for the farm where the data was collected.\n",
    "   - Datatype: `str`\n",
    "   - Example: `a624fb9a`\n",
    "\n",
    "3. **SE_Number**:\n",
    "   - Description: A unique identifier for the cow, which has been formatted to include the farm and the animal number.\n",
    "   - Datatype: `str`\n",
    "   - Example: `SE-064c0cec-1189`\n",
    "\n",
    "4. **Age**:\n",
    "   - Description: The age of the cow in days.\n",
    "   - Datatype: `Int64`\n",
    "   - Example: `3095`\n",
    "\n",
    "5. **BreedName**:\n",
    "   - Description: The breed name of the cow.\n",
    "   - Datatype: `str`\n",
    "   - Example: `02 SLB`\n",
    "\n",
    "6. **LactationNumber**:\n",
    "   - Description: The number assigned to the cow's lactation cycle.\n",
    "   - Datatype: `Int64`\n",
    "   - Example: `7`\n",
    "\n",
    "7. **DaysInMilk**:\n",
    "   - Description: The number of days the cow has been in milk (lactating) at the time of recording.\n",
    "   - Datatype: `Int64`\n",
    "   - Example: `191`\n",
    "\n",
    "8. **YearSeason**:\n",
    "   - Description: The seasonal period based on the year and the month range.\n",
    "   - Datatype: `str`\n",
    "   - Example: `2022-1`\n",
    "   - YearSeason parameters in yield datasets:\n",
    "     - 1: Dec-Feb\n",
    "     - 2: Mar-May\n",
    "     - 3: Jun-Aug\n",
    "     - 4: Sep-Nov\n",
    "\n",
    "9. **DailyYield**:\n",
    "   - Description: The total amount of milk produced by the cow in a single day.\n",
    "   - Datatype: `float`\n",
    "   - Example: `30.77`\n",
    "\n",
    "10. **PreviousDailyYield**:\n",
    "    - Description: The total amount of milk produced by the cow on the previous day.\n",
    "    - Datatype: `float`\n",
    "    - Example: `0.0`\n",
    "\n",
    "11. **DailyYieldChange**:\n",
    "    - Description: The change in daily milk yield from the previous day.\n",
    "    - Datatype: `float`\n",
    "    - Example: `0.0`\n",
    "\n",
    "12. **ExpectedYield**:\n",
    "    - Description: The expected amount of milk yield based on certain models or predictions.\n",
    "    - Datatype: `float`\n",
    "    - Example: `35.914865`\n",
    "\n",
    "13. **NormalizedDailyYield**:\n",
    "    - Description: The daily yield normalized to account for various factors.\n",
    "    - Datatype: `float`\n",
    "    - Example: `0.856748`\n",
    "\n",
    "14. **NormalizedDailyYieldChange**:\n",
    "    - Description: The change in normalized daily yield from the previous day.\n",
    "    - Datatype: `float`\n",
    "    - Example: `0.0`\n",
    "\n",
    "15. **HeatStress**:\n",
    "    - Description: A binary variable indicating the presence of heat stress on the cow.\n",
    "    - Datatype: `Int64`\n",
    "    - Example: `0`\n",
    "\n",
    "16. **Temp15Threshold**:\n",
    "    - Description: A binary variable indicating if the temperature exceeded 15 degrees Celsius on the given day.\n",
    "    - Datatype: `Int64`\n",
    "    - Example: `0`\n",
    "\n",
    "17. **HW**:\n",
    "    - Description: A binary variable indicating the presence of a heatwave on the day.\n",
    "    - Datatype: `Int64`\n",
    "    - Example: `0`\n",
    "\n",
    "18. **cum_HW**:\n",
    "    - Description: Cumulative number of heatwave days up to the current date.\n",
    "    - Datatype: `Int64`\n",
    "    - Example: `0`\n",
    "\n",
    "19. **MeanTemperature**:\n",
    "    - Description: The mean temperature recorded on the day.\n",
    "    - Datatype: `float`\n",
    "    - Example: `-3.025`\n",
    "\n",
    "20. **MeanTHI_adj**:\n",
    "    - Description: The mean adjusted Temperature-Humidity Index for the day.\n",
    "    - Datatype: `float`\n",
    "    - Example: `28.012944`\n",
    "\n",
    "21. **FarmHeatStressMilkProduction**:\n",
    "    - Description: The relative change in milk production based on farm and heat stress conditions.\n",
    "    - Datatype: `float`\n",
    "    - Example: `0.009435`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GIGACOW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
